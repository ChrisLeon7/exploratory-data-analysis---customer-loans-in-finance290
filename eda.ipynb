{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA on Finance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will focus on the Exploratory Data Analysis of the financail loans dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## necessary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformation import DataFrameTransform\n",
    "from db_utils import RDSDatabaseConnector\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loans csv extracted from the AWS RDS was previously extracted and saved locally. This is now loaded in as pandas to allow the use of EDA techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_payments.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensuring Columns are correct Datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below gives me some useful information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = DataFrameTransform(df)\n",
    "\n",
    "null_values_before = transformer.check_null_values()\n",
    "print(\"NULL values before imputation:\")\n",
    "print(null_values_before)\n",
    "\n",
    "\n",
    "transformer.impute_missing_values(strategy='mean')\n",
    "null_values_after = transformer.check_null_values_after()\n",
    "print(\"\\nNULL values after imputation:\")\n",
    "print(null_values_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created the DataFrameTransform class to facilitate data processing on the dataframe. First, I used check_null_values method return a dictionary with the count of NULL values in each column of the dataframe. \n",
    "\n",
    "The drop_columns method allows me for the removal of specified columns from the DataFrame.\n",
    "\n",
    "For handling missing numeric data, the impute_missing_values method allows me to find the median and mean. \n",
    "\n",
    "The check_null_values_after method reports the count of NULL values in each column. \n",
    "\n",
    "The drop_columns_with_high_null_percentage identifies columns in dataframe where the percentage of NULL values exceeds a specified threshold, which I set to 50%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformation import Plotter\n",
    "\n",
    "plotter = Plotter(df)\n",
    "plotter.plot_null_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skewed columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the identify_skewed_columns method from my DataFrameTransform class to find columns in the dataset that have skewness greater than 75%. This method gives me a list of these skewed columns, stored in skewed_columns. \n",
    "\n",
    "Next, I decided to transform these skewed columns using transform_skewed_columns. This method applies a transformation to numeric columns that exhibit skewness over teh 75% mentioned before. \n",
    "\n",
    "Finally, I printed out skewed_columns to see which columns were identified as skewed. This step helps me understand which columns require transformation based on their skewness levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(transformer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformation import DataTransform\n",
    "transformer = DataTransform(df)\n",
    "\n",
    "skewed_columns = transformer.identify_skewed_columns()\n",
    "transformer.transform_skewed_columns(skewed_columns)\n",
    "transformer.visualize_skewness(skewed_columns)\n",
    "transformer.save_dataframe('transformed_loan_payments.csv')\n",
    "\n",
    "print(\"Identified skewed columns:\")\n",
    "print(skewed_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I aim to identify the outlier and remove them by adding functions to the DataTransform and the Plotter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformation import DataTransform\n",
    "\n",
    "df = pd.read_csv('loan_payments.csv')\n",
    "\n",
    "\n",
    "transformer = DataTransform(df)\n",
    "\n",
    "\n",
    "transformer.plot_outliers()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
